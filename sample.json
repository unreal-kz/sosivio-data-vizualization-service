[
    {
        "whatHappened": "The container has not passed the readiness probe.",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "Container is not ready to serve connections"
    },
    {
        "whatHappened": "One of the Pod's containers is not in running state.",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "Container is not running."
    },
    {
        "whatHappened": "One or more containers running under this Pod exited and are not in running state.",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "One or more of the Pod's containers are not running."
    },
    {
        "whatHappened": "The Pod is not servicing requests - probably due to the readiness probe failure.",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "Pod is not operational."
    },
    {
        "whatHappened": "The Pod's basic operation conditions are not met.",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "The Pod is not running or not scheduled."
    },
    {
        "whatHappened": "The Pod's basic operation conditions are not met.",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "The Pod is not scheduled."
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<containeriddocker>>> : Consumed <*> <<<word:CPU>>> time.",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "container id consumed cpu time."
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<containeriddocker>>> : Succeeded.",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "container id succeeded."
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<context>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "context"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<word:Created>>> slice libcontainer container <<<kubepodspodid>>> .slice.",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "created slice libcontainer container kubepodspod unique id slice."
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> crio- <<<digest>>> .scope: Consumed <*> <*> <<<word:CPU>>> time.",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "crio digest scope consumed cpu time."
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<criotime>>> Z\" <*> <*> <*> <*> <*> <*> <*> <*>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<criotime>>> <*> <<<sourceprocessgoproc>>> Added Mac, interface name, and active container ID to endpoint <<<containeridlowerandcapital>>> <<<namespace-equals>>> <<<podequalscapital>>> <<<workload>>> endpoint= <<<goobject>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime goproc added mac, interface name, and active container to endpoint containeridlowerandcapital namespace equals podequalscapital workload endpoint goobject"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<criotime>>> <*> <<<sourceprocessgoproc>>> Affinity is confirmed and block has been loaded cidr= <<<ip>>> <<<hostequals>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime goproc affinity is confirmed and block has been loaded cidr ip hostequals"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<criotime>>> <*> <<<sourceprocessgoproc>>> Attempting to assign <<<genericnumber>>> addresses from block block= <<<ip>>> handle=\"k8s-pod-network. <<<digest>>> \" <<<hostequals>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime goproc attempting to assign genericnumber addresses from block ip handle k8s pod network. digest hostequals"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<criotime>>> <*> <<<sourceprocessgoproc>>> Attempting to load block cidr= <<<ip>>> <<<hostequals>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime goproc attempting to use the node assigned sdn ip addresses ip hostequals"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<criotime>>> <*> <<<sourceprocessgoproc>>> Auto-assign <<<genericnumber>>> ipv4, <<<genericnumber>>> ipv6 addrs <<<forhost>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime goproc auto assign genericnumber ipv4, genericnumber ipv6 addrs forhost"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<criotime>>> <*> <<<sourceprocessgoproc>>> Auto-assigned <<<genericnumber>>> out of <<<genericnumber>>> IPv4s: [ <<<ip>>> ] handle=\"k8s-pod-network. <<<digest>>> \" <<<hostequals>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime goproc auto assigned genericnumber out of genericnumber ipv4s ip handle k8s pod network. digest hostequals"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<criotime>>> <*> <<<sourceprocessgoproc>>> Auto assigning IP <<<containeridlowerandcapital>>> HandleID=\"k8s-pod-network. <<<digest>>> \" <<<workload>>> assignArgs= <<<AutoAssignArgs>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime goproc auto assigning ip containeridlowerandcapital handle k8s pod network. digest workload assignargs autoassignargs"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<criotime>>> <*> <<<sourceprocessgoproc>>> Calico CNI <*> device in netns /var/run/netns/ <<<podid2>>> <<<containeridlowerandcapital>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime goproc calico container network interface sdn device in netns var run netns containeridlowerandcapital"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<criotime>>> <*> <<<sourceprocessgoproc>>> Calico CNI found existing endpoint: <<<workendpoint>>> <<<containeridlowerandcapital>>> <<<namespace-equals>>> <<<podequalscapital>>> <<<workload>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime goproc calico container network interface sdn found existing endpoint workendpoint containeridlowerandcapital namespace equals podequalscapital workload"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<criotime>>> <*> <<<sourceprocessgoproc>>> Calico CNI IPAM assigned addresses IPv4=[ <<<ip>>> ] IPv6=[] <<<containeridlowerandcapital>>> HandleID=\"k8s-pod-network. <<<digest>>> \" <<<workload>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime goproc calico container network interface sdn ip address management assigned addresses ipv4 ip ipv6 containeridlowerandcapital handle k8s pod network. digest workload"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<criotime>>> <*> <<<sourceprocessgoproc>>> Calico CNI IPAM request count IPv4=1 IPv6=0 <<<containeridlowerandcapital>>> HandleID=\"k8s-pod-network. <<<digest>>> \" <<<workload>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime goproc calico container network interface sdn ip address management request count ipv4 ipv6 containeridlowerandcapital handle k8s pod network. digest workload"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<criotime>>> <*> <<<sourceprocessgoproc>>> Calico CNI <<<word:releasing>>> IP address <<<containeridlowerandcapital>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime goproc calico container network interface sdn releasing ip address containeridlowerandcapital"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<criotime>>> <*> <<<sourceprocessgoproc>>> Calico CNI using IPs: [ <<<ip>>> ] <<<containeridlowerandcapital>>> <<<namespace-equals>>> <<<podequalscapital>>> <<<workload>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime goproc calico container network interface sdn using ips ip containeridlowerandcapital namespace equals podequalscapital workload"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<criotime>>> <*> <<<sourceprocessgoproc>>> <<<word:Cleaning>>> up netns <<<containeridlowerandcapital>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime goproc cleaning up netns containeridlowerandcapital"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<criotime>>> <*> <<<sourceprocessgoproc>>> Creating new handle: k8s-pod-network. <<<digest>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime goproc creating new handle k8s pod network. digest"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<criotime>>> <*> <<<sourceprocessgoproc>>> Disabling IPv4 forwarding <<<containeridlowerandcapital>>> <<<namespace-equals>>> <<<podequalscapital>>> <<<workload>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime goproc disabling ipv4 forwarding containeridlowerandcapital namespace equals podequalscapital workload"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<criotime>>> <*> <<<sourceprocessgoproc>>> Extracted identifiers for CmdAddK8s <<<containeridlowerandcapital>>> <<<namespace-equals>>> <<<podequalscapital>>> <<<workload>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime goproc extracted identifiers for cmdaddk8s containeridlowerandcapital namespace equals podequalscapital workload"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<criotime>>> <*> <<<sourceprocessgoproc>>> Looking up existing affinities for host handle=\"k8s-pod-network. <<<digest>>> \" <<<hostequals>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime goproc node is trying to find free ip addresses on the node handle k8s pod network. digest hostequals"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<criotime>>> <*> <<<sourceprocessgoproc>>> Looking up existing affinities for host <<<hostequals>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime goproc node is trying to find free ip addresses on the node hostequals"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<criotime>>> <*> <<<sourceprocessgoproc>>> Populated endpoint <<<containeridlowerandcapital>>> <<<namespace-equals>>> <<<podequalscapital>>> <<<workload>>> endpoint= <<<goobject>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime goproc populated endpoint containeridlowerandcapital namespace equals podequalscapital workload endpoint goobject"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<criotime>>> <*> <<<sourceprocessgoproc>>> Released address using handleID <<<containeridlowerandcapital>>> HandleID=\"k8s-pod-network. <<<digest>>> \" <<<workload>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime goproc released address using handleid containeridlowerandcapital handle k8s pod network. digest workload"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<criotime>>> <*> <<<sourceprocessgoproc>>> <<<word:Releasing>>> address using <*> <<<containeridlowerandcapital>>> HandleID=\"k8s-pod-network. <<<digest>>> \" <<<workload>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime goproc releasing address using containeridlowerandcapital handle k8s pod network. digest workload"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<criotime>>> <*> <<<sourceprocessgoproc>>> <<<word:Releasing>>> IP address(es) <<<containeridlowerandcapital>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime goproc releasing ip address es containeridlowerandcapital"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<criotime>>> <*> <<<sourceprocessgoproc>>> Setting the host side veth name to <*> <<<containeridlowerandcapital>>> <<<namespace-equals>>> <<<podequalscapital>>> <<<workload>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime goproc setting the host side virtual ethernet device name to containeridlowerandcapital namespace equals podequalscapital workload"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<criotime>>> <*> <<<sourceprocessgoproc>>> Successfully claimed IPs: [ <<<ip>>> ] block= <<<ip>>> handle=\"k8s-pod-network. <<<digest>>> \" <<<hostequals>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime goproc successfully claimed ips ip block ip handle k8s pod network. digest hostequals"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<criotime>>> <*> <<<sourceprocessgoproc>>> <<<word:Teardown>>> processing complete. <<<containeridlowerandcapital>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime goproc teardown processing complete. containeridlowerandcapital"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<criotime>>> <*> <<<sourceprocessgoproc>>> Trying affinity for <<<ip>>> <<<hostequals>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime goproc trying affinity for ip hostequals"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<criotime>>> <*> <<<sourceprocessgoproc>>> Writing block in order to <<<pvcclaimevent>>> block= <<<ip>>> handle=\"k8s-pod-network. <<<digest>>> \" <<<hostequals>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime goproc writing block in order to persistent volume claim block ip handle k8s pod network. digest hostequals"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<criotime>>> <*> <<<sourceprocessgoproc>>> Wrote updated endpoint to datastore <<<containeridlowerandcapital>>> <<<namespace-equals>>> <<<podequalscapital>>> <<<workload>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime goproc wrote updated endpoint to datastore containeridlowerandcapital namespace equals podequalscapital workload"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<criotime>>> Z\" level=info <*> <*> <*> <*> <*> <*> <*> <*>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime level info"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<criotime>>> Z\" level=info <*> container: <<<digest>>> \" id= <<<podid2>>> <*>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime level info container digest"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<criotime>>> Z\" level=info <*> <<<containerid;namespace;pod;containername>>> \" id= <<<podid2>>> <*>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime level info container for pod in namespace"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<criotime>>> Z\" level=info <*> <*> <*> <*> <*> <<<digest>>> \" id= <<<podid2>>> <*>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime level info digest"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<criotime>>> Z\" level=info msg=\" <<<image-not-found-id>>> name=/runtime.v1.ImageService/ImageStatus",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime level info image not found id name runtime .imageservice imagestatus"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<criotime>>> Z\" level=info msg=\" <<<imagenotfound>>> <<<goobject>>> \" id= <<<podid2>>> name=/runtime.v1.ImageService/ImageStatus",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime level info imagenotfound goobject name runtime .imageservice imagestatus"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<criotime>>> Z\" level=info msg=\"Checking image status: <<<image-format-with-space-or-quotes>>> \" id= <<<podid2>>> name=/runtime.v1.ImageService/ImageStatus",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime level info msg checking image status container image name runtime .imageservice imagestatus"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<criotime>>> Z\" level=info msg=\"Pulling image: <<<image-format-with-space-or-quotes>>> \" id= <<<podid2>>> name=/runtime.v1.ImageService/PullImage",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime level info msg container image is being downloaded to the node container image name runtime .imageservice container image being downloaded"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<criotime>>> Z\" level=info msg=\"Got pod network & <<<jsonobject>>> \"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime level info msg got pod network jsonobject"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<criotime>>> Z\" level=info msg=\"Ran pod sandbox <<<digest>>> with inf <<<namespace;pod;containername>>> \" id= <<<podid2>>> name=/runtime.v1.RuntimeService/RunPodSandbox",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime level info msg ran pod the container filesystem digest with inf namespace pod container name runtime .runtimeservice runpod the container filesystem"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<criotime>>> Z\" level=info msg=\"Running pod sandbox: <*> id= <<<podid2>>> name=/runtime.v1.RuntimeService/RunPodSandbox",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime level info msg running pod the container filesystem name runtime .runtimeservice runpod the container filesystem"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<criotime>>> Z\" level=info msg=\"Started container\" <*> containerID= <<<digest>>> <*> id= <<<podid2>>> name=/runtime.v1.RuntimeService/StartContainer sandboxID= <<<digest>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime level info msg started container digest name runtime .runtimeservice start container command the container filesystem digest"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<criotime>>> Z\" level=info msg=\"Stopping container: <<<digest>>> (timeout: <*> id= <<<podid2>>> name=/runtime.v1.RuntimeService/StopContainer",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime level info msg stopping container digest timeout name runtime .runtimeservice stopping container"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<criotime>>> Z\" level=info msg=\"Trying to access \\ <<<image-format-with-space-or-quotes>>> \\\"\"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime level info msg trying to access container image"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<criotime>>> Z\" level=info msg=\" <<<namespace;pod;containername>>> \" id= <<<podid2>>> name=/runtime.v1.RuntimeService/CreateContainer",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime level info namespace pod container name runtime .runtimeservice createcontainer"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<criotime>>> Z\" level=info <*> pod sandbox: <<<digest>>> \" id= <<<podid2>>> <*>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime level info pod the container filesystem digest"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<criotime>>> Z\" level=info msg=\" <<<pulledimage>>> <<<code path>>> 256 <<<imagesha256>>> \" id= <<<podid2>>> name=/runtime.v1.ImageService/PullImage",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime level info pulledimage code path 256 imagesha256 name runtime .imageservice container image being downloaded"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<criotime>>> Z\" level=warning msg=\"Failed to open <*> open / <<<image>>> <*> no such file or directory\"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "criotime level warning msg failed to open image tried to open file or change to directory which was not found"
    },
    {
        "whatHappened": "<<<deploymentid;deployment;namespace>>> Reason:ScalingReplicaSet Type:Normal <<<scaled-down-replica-set>>> <*>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "deploymentid deployment namespace scalingreplicaset normal scaled down replica set"
    },
    {
        "whatHappened": "<<<deploymentid;deployment;namespace>>> Reason:ScalingReplicaSet Type:Normal <<<scaled-up-replica-set>>> <*>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "deploymentid deployment namespace scalingreplicaset normal scaled up replica set"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <*> <<<digest>>> <*> Succeeded.",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "digest succeeded."
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<docker-time-stamp>>> \" level=info <*> host-wide IPAM lock.\" source=\" <<<gofilelinenumber>>> \"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "docker time stamp level info host wide ip address management lock. source gofilelinenumber"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<docker-time-stamp>>> \" level=info msg=\"About to acquire host-wide IPAM lock.\" source=\" <<<gofilelinenumber>>> \"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "docker time stamp level info msg about to acquire host wide ip address management lock. source gofilelinenumber"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<dockertimestamp>>> \" level=error msg=\"Handler for POST /v1.41/images/create <<<word:returned>>> error: <<<headurl>>> dial tcp: <<<lookupdns>>> <<<ip;port>>> : no such host\"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "error msg handler for post 41 images create returned failed http url trying to open tcp connection dns resolution failed"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<dockertimestamp>>> \" level=error msg=\"Handler for POST /v1.41/images/create <<<word:returned>>> error: unauthorized: authentication required\"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "error msg handler for post 41 images create returned failed not authorized authentication required"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<dockertimestamp>>> \" level=error msg=\"(*service).Write failed\" error=\"rpc error: code = FailedPrecondition desc = unexpected commit digest sha256 <<<imagesha256>>> , expected sha256 <<<imagesha256>>> : <<<word:failed>>> precondition\" expected=\"sha256 <<<imagesha256>>> \" ref=\"unknown-sha256 <<<imagesha256>>> \" total=17821",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "error msg service write failed error remote procedure failed failedprecondition desc container image corrupt imagesha256 expected sha256 imagesha256 failed precondition expected sha256 imagesha256 ref sha256 imagesha256 total 17821"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<file-comparison>>> for changes",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "file comparison for changes"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<word:Finished>>> <*> <*> <*> <*> <*> <*> <*>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "finished"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<imagevarlibdockeroverlay>>> <*> Succeeded.",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "imagevarlibdockeroverlay succeeded."
    },
    {
        "whatHappened": "<<<DateTimeutc>>> kernel[] <*>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "kernel"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> kernel[] anon <<<genericnumber>>> file <<<genericnumber>>> kernel_stack <<<genericnumber>>> slab <<<genericnumber>>> sock <<<genericnumber>>> shmem <<<genericnumber>>> file_mapped <<<genericnumber>>> file_dirty <<<genericnumber>>> file_writeback <<<genericnumber>>> anon_thp <<<genericnumber>>> inactive_anon <<<genericnumber>>> active_anon <<<genericnumber>>> inactive_file <<<genericnumber>>> active_file <<<genericnumber>>> unevictable <<<genericnumber>>> slab_reclaimable <<<genericnumber>>> slab_unreclaimable <<<genericnumber>>> pgfault <<<genericnumber>>> pgmajfault <<<genericnumber>>> workingset_refault <<<genericnumber>>> workingset_activate <<<genericnumber>>> workingset_nodere <<<pvcclaimevent>>> pgrefill <<<genericnumber>>> pgscan <<<genericnumber>>> pgsteal <<<genericnumber>>> pgactivate <<<genericnumber>>> pgdeactivate <<<genericnumber>>> pglazyfree <<<genericnumber>>> pglazyfreed <<<genericnumber>>> thp_fault_alloc <<<genericnumber>>> thp_collapse_alloc <*>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "kernel anon genericnumber file genericnumber kernel stack genericnumber slab genericnumber sock genericnumber shmem genericnumber file mapped genericnumber file dirty genericnumber file writeback genericnumber anon thp genericnumber inactive anon genericnumber active anon genericnumber inactive file genericnumber active file genericnumber unevictable genericnumber slab reclaimable genericnumber slab unreclaimable genericnumber pgfault genericnumber pgmajfault genericnumber workingset refault genericnumber workingset activate genericnumber workingset nodere persistent volume claim pgrefill genericnumber pgscan genericnumber pgsteal genericnumber pgactivate genericnumber pgdeactivate genericnumber pglazyfree genericnumber pglazyfreed genericnumber thp fault alloc genericnumber thp collapse alloc"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> kernel[] <<<word:CPU>>> <<<genericnumber>>> <<<capitalpid>>> <<<processname>>> Tainted: G OE <*> <*>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "kernel cpu genericnumber capitalprocess id process name tainted oe"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> kernel[] IPv6: <<<netdeviceaddrconf>>> link becomes ready",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "kernel ipv6 netdeviceaddrconf link becomes ready"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> kernel[] ISO <<<genericnumber>>> Extensions: Microsoft Joliet Level 3",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "kernel iso genericnumber extensions microsoft joliet level"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> kernel[] ISO <<<genericnumber>>> Extensions: RRIP_1991A",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "kernel iso genericnumber extensions rrip 1991a"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> kernel[] <<<kernelcode>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "kernel kernelcode"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> kernel[] <<<word:Memory>>> cgroup out of <<<word:memory>>> <<<killedpid;processname>>> <<<totalvm>>> , <<<anonrss>>> , <<<filerss>>> , <<<shmemrss>>> , <*> <*> <*>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "kernel memory control group out of memory killedprocess id process name totalvm anonphysical memory consumed filephysical memory consumed shmemphysical memory consumed"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> kernel[] <<<word:Memory>>> cgroup stats for <<<pod-from-slice>>> :",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "kernel memory control group stats for pod from slice"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> kernel[] <<<word:memory>>> usage <*> limit <*> failcnt <*>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "kernel memory usage limit failure count"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> kernel[] oom-kill:constraint=CONSTRAINT_MEMCG,nodemask=(null),cpuset= <<<containeriddocker>>> ,mems_allowed=0,oom_memcg= <<<pod-from-slice>>> ,task_memcg= <<<pod-from-slice>>> / <<<containeriddocker>>> , <<<processnamefromkerneltask>>> <<<pidequalsclear>>> <*>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "kernel out of memory kill constraint memory control group nodemask null cpuset container id no more memory is allowed for the process the process will probably will cause process failure and be terminated out of memory control group pod from slice task memory control group pod from slice container id process name process id"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> kernel[] oom-kill:constraint=CONSTRAINT_MEMCG,nodemask=(null),cpuset=crio- <<<digest>>> .scope,mems_allowed=0,oom_memcg= <<<pod-from-slice>>> ,task_memcg= <<<pod-from-slice>>> /crio- <<<digest>>> .scope, <<<processnamefromkerneltask>>> <<<pidequalsclear>>> <*>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "kernel out of memory kill constraint memory control group nodemask null cpuset crio digest scope no more memory is allowed for the process the process will probably will cause process failure and be terminated out of memory control group pod from slice task memory control group pod from slice crio digest scope, process name process id"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> kernel[] <<<pid;processnameexact>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "kernel process id process nameexact"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> kernel[] [ pid ] uid tgid total_vm rss pgtables_bytes swapents oom_score_adj name",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "kernel process id uid tgid total vm physical memory consumed pgtables bytes swapents out of memory score adjustment name"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> kernel[] <<<process-name-invoked-oom-killer>>> <*> <*> <<<oom-score-changed>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "kernel process name invoked out of memory killer out of memory score changed"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> kernel[] oom_reaper: <<<reapedprocess;processname>>> , now <<<anonrss>>> , <<<filerss>>> , <<<shmemrss>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "kernel process was killed by out of memory killer due to high memory consumption causing the kernel to terminate the process agressivly terminated process name now anonphysical memory consumed filephysical memory consumed shmemphysical memory consumed"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> kernel[] <<<reg-address>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "kernel reg address"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> kernel[] <<<reg-address>>> <<<eflags>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "kernel reg address eflags"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> kernel[] <<<reg-address>>> <<<reg-address>>> <<<reg-address>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "kernel reg address reg address reg address"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> kernel[] Tasks state (memory values in pages):",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "kernel tasks state memory values in pages"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> kernel[] <<<kernel-trap-process>>> <<<invalid-opcode-library>>> <*>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "kernel trap process invalid opcode library"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<kubepodspodid>>> .slice: Consumed <*> <<<word:CPU>>> time.",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "kubepodspod unique id slice consumed cpu time."
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<dockertimestamp>>> \" level=info msg=\"Attempting next endpoint for pull after error: <<<headurl>>> dial tcp: <<<lookupdns>>> <<<ip;port>>> : no such host\"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "level info msg attempting next endpoint for pull after failed http url trying to open tcp connection dns resolution failed"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<dockertimestamp>>> \" level=info msg=\"Attempting next endpoint for pull after error: unauthorized: authentication required\"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "level info msg attempting next endpoint for pull after failed not authorized authentication required"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<dockertimestamp>>> \" level=info msg=\"cleaning up dead shim\"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "level info msg cleaning up dead shim"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<dockertimestamp>>> \" level=info msg=\"ignoring event\" <<<containeridequals>>> module=libcontainerd namespace=moby topic=/tasks/delete type=\"*events.TaskDelete\"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "level info msg ignoring event containeridequals module libcontainerd namespace moby topic tasks delete type events taskdelete"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<dockertimestamp>>> \" level=info msg=\"shim disconnected\" <<<containerididequals>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "level info msg shim disconnected containerididequals"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<dockertimestamp>>> \" level=info msg=\"starting signal loop\" namespace=moby path=/run/containerd <<<containerid;pid>>> <*>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "level info msg starting signal loop namespace moby path run containerd container process id"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<dockertimestamp>>> \" level=warning msg=\"cleaning up after shim disconnected\" id= <<<digest>>> namespace=moby",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "level warning msg cleaning up after shim disconnected digest namespace moby"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<dockertimestamp>>> \" level=warning msg=\"cleanup warnings time=\\\" <<<docker-time-stamp>>> \\\" level=info msg=\\\"starting signal loop\\\" namespace=moby <<<pidequalsclear>>> \\n\"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "level warning msg cleanup warnings time docker time stamp level info msg starting signal loop namespace moby process id"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<dockertimestamp>>> \" level=warning msg=\"Error getting v2 registry: <<<headurl>>> dial tcp: <<<lookupdns>>> <<<ip;port>>> : no such host\"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "level warning msg error getting v2 registry http url trying to open tcp connection dns resolution failed"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<dockertimestamp>>> \" level=warning msg=\"Error persisting manifest\" digest=\"sha256 <<<imagesha256>>> \" error=\"error committing manifest to content store: commit <<<word:failed>>> unexpected commit digest sha256 <<<imagesha256>>> , expected sha256 <<<imagesha256>>> : <<<word:failed>>> precondition\" remote= <<<image-format-with-space-or-quotes>>> \"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "level warning msg error persisting manifest digest sha256 imagesha256 error committing manifest to content store commit failed container image corrupt imagesha256 expected sha256 imagesha256 failed precondition remote container image"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<dockertimestamp>>> \" level=warning msg=\"reference for unknown type: application/vnd.docker.distribution.manifest.v1+prettyjws\" digest=\"sha256 <<<imagesha256>>> \" remote= <<<image-format-with-space-or-quotes>>> \"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "level warning msg reference for application vnd docker distribution manifest. prettyjws digest sha256 imagesha256 remote container image"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> time=\" <<<dockertimestamp>>> \" level=warning msg=\"Your kernel does not support swap limit capabilities or the cgroup is not mounted. <<<word:Memory>>> limited without swap.\"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "level warning msg your kernel does not support swap limit capabilities or the control group is not mounted. memory limited without swap."
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<mount>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "mount"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<netdeviceprecise>>> : autonegotiation is unset or enabled, the speed and duplex are not writable.",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "netdeviceprecise autonegotiation is unset or enabled, the speed and duplex are not writable."
    },
    {
        "whatHappened": "<<<podid;pod;namespace>>> Reason:BackOff Type:Normal Back-off pulling image <<<image-format-with-space-or-quotes>>> \"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "pod in namespace back off normal back off container image is being downloaded to the node container image"
    },
    {
        "whatHappened": "<<<podid;pod;namespace>>> Reason:BackOff Type:Warning Back-off restarting <<<word:failed>>> container",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "pod in namespace back off warning back off restarting failed container"
    },
    {
        "whatHappened": "<<<podid;pod;namespace>>> Reason:Created Type:Normal <<<created-container-name>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "pod in namespace created normal created container name"
    },
    {
        "whatHappened": "<<<podid;pod;namespace>>> Reason:ErrImageNeverPull Type:Warning Container image <<<image-format-with-space-or-quotes>>> \" is not present with pull policy of Never",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "pod in namespace error image pull policy is set to never pull warning container image container image is not present with pull policy of never"
    },
    {
        "whatHappened": "<<<podid;pod;namespace>>> Reason:FailedMount Type:Warning (combined from similar events): MountVolume.SetUp <<<word:failed>>> <<<volumeforvolume>>> : write /var/lib/kubelet/pods/ <<<podid2>>> <*> no space left on device",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "pod in namespace failed to mount disk warning combined from similar events mounting volume to pod setup failed volumeforvolume write containers sandbox mount on the kubernetes node no space left on device"
    },
    {
        "whatHappened": "<<<podid;pod;namespace>>> Reason:FailedMount Type:Warning MountVolume.SetUp <<<word:failed>>> <<<volumeforvolume>>> : <<<configmap-not-found>>> not found",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "pod in namespace failed to mount disk warning mounting volume to pod setup failed volumeforvolume configmap configured for the pod does not exist"
    },
    {
        "whatHappened": "<<<podid;pod;namespace>>> Reason:FailedMount Type:Warning Unable to attach or mount volumes: unmounted <<<volumes-for-pod>>> , unattached <<<volumes-for-pod>>> : <<<word:timed>>> out waiting for the condition",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "pod in namespace failed to mount disk warning unable to attach or mount volumes unmounted volumes for pod unattached volumes for pod timed out waiting for the condition"
    },
    {
        "whatHappened": "<<<podid;pod;namespace>>> Reason:FailedScheduling Type:Warning <<<NoneNodesFound>>> <<<insufficient>>> <<<word:cpu>>> <<<insufficientnodes>>> didn't match Pod's <<<node-name-endpoint>>> /selector.",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "pod in namespace failed to schedule pod on node warning could not find available node insufficient cpu found on cluster node with enough cpu to deploy this pod could not be found insufficientnodes didn match pod node name endpoint selector."
    },
    {
        "whatHappened": "<<<podid;pod;namespace>>> Reason:FailedScheduling Type:Warning <<<NoneNodesFound>>> <<<taints>>> , that the pod didn't tolerate <<<insufficientnodes>>> didn't match pod affinity rules.",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "pod in namespace failed to schedule pod on node warning could not find available node taints that the pod didn tolerate insufficientnodes didn match pod affinity rules."
    },
    {
        "whatHappened": "<<<podid;pod;namespace>>> Reason:FailedScheduling Type:Warning <<<NoneNodesFound>>> <<<taints>>> , that the pod didn't tolerate <<<insufficientnodes>>> didn't match Pod's <<<node-name-endpoint>>> /selector.",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "pod in namespace failed to schedule pod on node warning could not find available node taints that the pod didn tolerate insufficientnodes didn match pod node name endpoint selector."
    },
    {
        "whatHappened": "<<<podid;pod;namespace>>> Reason:FailedScheduling Type:Warning <<<NoneNodesFound>>> <<<taints>>> , that the pod didn't tolerate, <<<insufficient>>> <<<word:cpu>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "pod in namespace failed to schedule pod on node warning could not find available node taints that the pod didn tolerate, insufficient cpu found on cluster node with enough cpu to deploy this pod could not be found."
    },
    {
        "whatHappened": "<<<podid;pod;namespace>>> Reason:Failed Type:Warning <<<word:Failed>>> to pull image <<<image-format-with-space-or-quotes>>> \": rpc error: code = Unknown desc = <<<reading-manifest-failed>>> : manifest unknown: manifest unknown",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "pod in namespace failed warning failed to pull image container image remote procedure failed reading manifest failed container image manifest was not found in the container repository container image manifest was not found in the container repository"
    },
    {
        "whatHappened": "<<<podid;pod;namespace>>> Reason:InspectFailed Type:Warning <<<word:Failed>>> to apply default image tag \"<dockerRepo>/container-create-error:<release>\": couldn't parse image reference \"<dockerRepo>/container-create-error:<release>\": invalid reference format: repository name must be lowercase",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "pod in namespace inspectfailed warning failed to apply default image tag container repository container create failed release could not parse image reference container repository container create failed release invalid reference format repository name must be lowercase"
    },
    {
        "whatHappened": "<<<podid;pod;namespace>>> Reason:Killing Type:Normal <<<stoppingcontainername>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "pod in namespace killing normal stopping container"
    },
    {
        "whatHappened": "<<<podid;pod;namespace>>> Reason:Pulled Type:Normal (combined from similar events): Successfully pulled image <<<image-format-with-space-or-quotes>>> \" in <*>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "pod in namespace pulled normal combined from similar events successfully pulled image container image in"
    },
    {
        "whatHappened": "<<<podid;pod;namespace>>> Reason:Pulled Type:Normal Successfully pulled image <<<image-format-with-space-or-quotes>>> \" in <*>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "pod in namespace pulled normal successfully pulled image container image in"
    },
    {
        "whatHappened": "<<<podid;pod;namespace>>> Reason:Pulling Type:Normal Pulling image <<<image-format-with-space-or-quotes>>> \"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "pod in namespace pulling normal container image is being downloaded to the node container image"
    },
    {
        "whatHappened": "<<<podid;pod;namespace>>> Reason:Scheduled Type:Normal Successfully <<<namespace;pod;node>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "pod in namespace scheduled normal successfully pod in namespace on node"
    },
    {
        "whatHappened": "<<<podid;pod;namespace>>> Reason:Started Type:Normal <<<containerstarted>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "pod in namespace started normal containerstarted"
    },
    {
        "whatHappened": "<<<podid;pod;namespace>>> Reason:Unhealthy Type:Warning <<<livenessprobe-catch>>> <<<word:failed>>> <<<command-in-container-timed-out>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "pod in namespace unhealthy warning livenessprobe probe failed command in container timed out"
    },
    {
        "whatHappened": "<<<podid;pod;namespace>>> Reason:Unhealthy Type:Warning <<<livenessprobe-catch>>> <<<word:failed>>> <<<headurl>>> dial tcp <<<ip;port>>> : connect: <<<word:connection>>> <<<word:refused>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "pod in namespace unhealthy warning livenessprobe probe failed http urlopen connection to the ip and port network connection attempted connection refused"
    },
    {
        "whatHappened": "<<<podid;pod;namespace>>> Reason:Unhealthy Type:Warning <<<readinessprobe-catch>>> <<<word:failed>>> <<<headurl>>> dial tcp <<<ip;port>>> : connect: <<<word:connection>>> <<<word:refused>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "pod in namespace unhealthy warning readiness probe failed http urlopen connection to the ip and port network connection attempted connection refused"
    },
    {
        "whatHappened": "<<<podid;pod;namespace>>> Reason:Unhealthy Type:Warning <<<readinessprobe-catch>>> <<<word:failed>>> <<<probe-failed-500>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "pod in namespace unhealthy warning readiness probe failed probe failed with http 500 response"
    },
    {
        "whatHappened": "<<<pvcid;pvc;namespace>>> Reason:FailedBinding Type:Normal no persistent volumes available for this <<<pvcclaimevent>>> no storage class is set",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "pvcid pvc namespace failedbinding normal no persistent volumes available for this persistent volume claim no storage class is set"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<word:Releasing>>> lock /var/run/one-context/one-context.lock",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "releasing lock var run one context one context lock"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<word:Removed>>> slice libcontainer container <<<kubepodspodid>>> .slice.",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "removed slice libcontainer container kubepodspod unique id slice."
    },
    {
        "whatHappened": "<<<replicasetid;replicaset;namespace>>> Reason:FailedCreate Type:Warning <<<errorcreatingpod>>> is forbidden: error looking up <<<namespace;serviceaccount>>> <<<serviceaccount>>> not found",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "replicasetid replicaset namespace failedcreate warning errorcreatingpod is forbidden error looking up namespace serviceaccount not found"
    },
    {
        "whatHappened": "<<<replicasetid;replicaset;namespace>>> Reason:FailedCreate Type:Warning <<<errorcreatingpod>>> is forbidden: no PriorityClass with name high-priority was found",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "replicasetid replicaset namespace failedcreate warning errorcreatingpod is forbidden no priorityclass with name high priority was found"
    },
    {
        "whatHappened": "<<<replicasetid;replicaset;namespace>>> Reason:SuccessfulCreate Type:Normal (combined from similar events): <<<pod-from-event-create2>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "replicasetid replicaset namespace successfulcreate normal combined from similar events pod from event create2"
    },
    {
        "whatHappened": "<<<replicasetid;replicaset;namespace>>> Reason:SuccessfulCreate Type:Normal <<<pod-from-event-create2>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "replicasetid replicaset namespace successfulcreate normal pod from event create2"
    },
    {
        "whatHappened": "<<<replicasetid;replicaset;namespace>>> Reason:SuccessfulDelete Type:Normal (combined from similar events): <<<deleted-pod>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "replicasetid replicaset namespace successfuldelete normal combined from similar events deleted pod"
    },
    {
        "whatHappened": "<<<replicasetid;replicaset;namespace>>> Reason:SuccessfulDelete Type:Normal <<<deleted-pod>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "replicasetid replicaset namespace successfuldelete normal deleted pod"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> run-docker-runtime\\x2 <<<modycontainerid>>> <*> Succeeded.",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "run docker runtime x2 modycontainerid succeeded."
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> <*> <*> <*>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> \"Cleaned up orphaned pod volumes dir\" podUID= <<<podid2>>> path=\"/var/lib/kubelet/pods/ <<<podid2>>> /volumes\"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile cleaned up orphaned pod volumes dir podu path containers sandbox mount on the kubernetes node volumes"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> container <<<containerobject>>> start <<<word:failed>>> in pod <<<pod;namespace;podid>>> : CreateContainerError: <<<word:failed>>> to generate security options <<<for-containername>>> <<<word:failed>>> to generate seccomp security options for container: <<<cannot-loca-seccomp-profile>>> no such file or directory",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile container start failed in pod in namespace container creation failed to generate security options for container failed to setup secure computing seccomp options for the container cannot loca seccomp profile tried to open file or change to directory which was not found"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> container <<<containerobject>>> start <<<word:failed>>> in pod <<<pod;namespace;podid>>> : <<<word:CreateContainerConfigError>>> <<<configmap-not-found>>> not found",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile container start failed in pod in namespace creating container configuration failed, either secret persistent volume or other pod configuration failed configmap configured for the pod does not exist"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> container <<<containerobject>>> start <<<word:failed>>> in pod <<<pod;namespace;podid>>> : <<<word:CreateContainerConfigError>>> <<<eventsecretnotfound>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile container start failed in pod in namespace creating container configuration failed, either secret persistent volume or other pod configuration failed secret not found"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> container <<<containerobject>>> start <<<word:failed>>> in pod <<<pod;namespace;podid>>> : ErrImagePull: rpc error: code = Unknown desc = Error response from daemon: unauthorized: authentication required",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile container start failed in pod in namespace error downloading container image remote procedure failed error response from remote process not authorized authentication required"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> container <<<containerobject>>> start <<<word:failed>>> in pod <<<pod;namespace;podid>>> : ErrImagePull: rpc error: code = Unknown desc = <*> <*> <*> <*> <<<headurl>>> dial tcp: <<<lookupdns>>> <<<ip;port>>> : no such host",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile container start failed in pod in namespace error downloading container image remote procedure failed http url trying to open tcp connection dns resolution failed"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> container <<<containerobject>>> start <<<word:failed>>> in pod <<<pod;namespace;podid>>> : ErrImagePull: rpc error: code = Unknown desc = <<<reading-manifest-failed>>> : manifest unknown: manifest unknown",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile container start failed in pod in namespace error downloading container image remote procedure failed reading manifest failed container image manifest was not found in the container repository container image manifest was not found in the container repository"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> container <<<containerobject>>> start <<<word:failed>>> in pod <<<pod;namespace;podid>>> : ErrImagePull: rpc error: code = Unknown desc = <<<reading-manifest-failed>>> : unauthorized: access to the requested resource is not authorized",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile container start failed in pod in namespace error downloading container image remote procedure failed reading manifest failed not authorized access to the requested resource is not authorized"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> container <<<containerobject>>> start <<<word:failed>>> in pod <<<pod;namespace;podid>>> : <<<word:ErrImageNeverPull>>> Container image <<<image-format-with-space-or-quotes>>> \" is not present with pull policy of Never",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile container start failed in pod in namespace error image pull policy is set to never pull container image container image is not present with pull policy of never"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> container <<<containerobject>>> start <<<word:failed>>> in pod <<<pod;namespace;podid>>> : InvalidImageName: <<<word:Failed>>> to apply default image tag \"<dockerRepo>/container-create-error:<release>\": couldn't parse image reference \"<dockerRepo>/container-create-error:<release>\": invalid reference format: repository name must be lowercase",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile container start failed in pod in namespace image failed to apply default image tag container repository container create failed release could not parse image reference container repository container create failed release invalid reference format repository name must be lowercase"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> Couldn't get <<<namespace;configmapprecisename>>> : <<<configmap-not-found>>> not found",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile could not get namespace configmapprecisename configmap configured for the pod does not exist"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> \"CreateContainer in sandbox from runtime service failed\" err=\"rpc error: code = Unknown desc = <<<word:failed>>> to generate security options <<<for-containername>>> <<<word:failed>>> to generate seccomp security options for container: <<<cannot-loca-seccomp-profile>>> no such file or directory\" <<<podsandboxidcontainerid>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile createcontainer in the container filesystem from runtime service failed err remote procedure failed to generate security options for container failed to setup secure computing seccomp options for the container cannot loca seccomp profile tried to open file or change to directory which was not found pod the container filesystem container id"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> \"DeleteContainer <<<word:returned>>> error\" <<<crio-containerid>>> err=\"failed to get container status \\\" <<<digest>>> \\\": rpc error: code = NotFound desc = <<<containerid-not-found>>> : container with ID <<<word:starting>>> with <<<digest>>> not found: ID does not exist\"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile deleting container returned error crio container err failed to get container status digest remote procedure failed notfound desc container not found container with id starting with digest not found id does not exist"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> \"RemoveContainer\" <<<containeridlowerandcapital>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile deleting the container containeridlowerandcapital"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> Error writing payload to dir: write /var/lib/kubelet/pods/ <<<podid2>>> <*> no space left on device",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile error writing payload to dir write containers sandbox mount on the kubernetes node no space left on device"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> \"Failed to get system container stats\" err=\"failed to get cgroup stats for \\\"/system.slice/kubelet.service\\\": <<<word:failed>>> to get container info for \\\"/system.slice/kubelet.service\\\": unknown container \\\"/system.slice/kubelet.service\\\"\" containerName=\"/system.slice/kubelet.service\"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile failed to get system container stats err failed to get control group stats for system slice kubelet service failed to get container info for system slice kubelet service container system slice kubelet service container system slice kubelet service"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> <<<word:Failed>>> to process watch event {EventType:0 Name: <<<pod-from-slice>>> /crio- <<<digest>>> .scope WatchSource:0}: Error finding container <<<digest>>> : Status <<<genericnumber>>> <<<word:returned>>> error <*> <nil> <nil> false false {0 0} false false false <nil>}) {%!s(int32=0) %!s(uint32=0)} %!s(bool=false) <nil> %!s(func(error) error=0x840ee0) %!s(func() error=0x840fe0)}",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile failed to process watch event event0 name pod from slice crio digest scope watchsource error finding container digest status genericnumber returned error non existent non existent false non existent int32 uint32 bool false non existent func error 0x840ee0 func error 0x840fe0"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> \"Failed to pull image\" err=\"rpc error: code = Unknown desc = <*> <*> <*> <*> <<<headurl>>> dial tcp: <<<lookupdns>>> <<<ip;port>>> : no such host\" image= <<<image-format-with-space-or-quotes>>> \"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile failed to pull image err remote procedure failed http url trying to open tcp connection dns resolution failed container image"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> \"Failed to pull image\" err=\"rpc error: code = Unknown desc = <<<reading-manifest-failed>>> : unauthorized: access to the requested resource is not authorized\" image= <<<image-format-with-space-or-quotes>>> \"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile failed to pull image err remote procedure failed reading manifest failed not authorized access to the requested resource is not authorized container image"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> <*> from runtime service failed\" err=\"rpc error: code = NotFound desc = <<<containerid-not-found>>> : container with ID <<<word:starting>>> with <<<digest>>> not found: ID does not exist\" <<<containeridlowerandcapital>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile from runtime service failed err remote procedure failed notfound desc container not found container with id starting with digest not found id does not exist containeridlowerandcapital"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> Operation for \"{volumeName:kubernetes.io/ <<<configmapevent>>> podName: <<<podid2>>> nodeName:}\" <<<word:failed>>> No retries permitted until <<<DateTimeutc>>> <<<mplusignore>>> (durationBeforeRetry 2m2s). Error: MountVolume.SetUp <<<word:failed>>> <<<volumeforvolume>>> (UniqueName: \"kubernetes.io/ <<<configmapevent>>> \") <<<pod-from-event-create>>> (UID: \" <<<podid2>>> \") : <<<configmap-not-found>>> not found",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile operation for volume name kubernetes io configmapevent pod node failed. no retries permitted until mplusignore duration failed mounting volume to pod setup failed volumeforvolume kubernetes io configmapevent pod from event create configmap configured for the pod does not exist"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> Operation for \"{volumeName:kubernetes.io/projected/ <<<podid3;volume>>> podName: <<<podid2>>> nodeName:}\" <<<word:failed>>> No retries permitted until <<<DateTimeutc>>> <<<mplusignore>>> (durationBeforeRetry <*> Error: MountVolume.SetUp <<<word:failed>>> <<<volumeforvolume>>> (UniqueName: \"kubernetes.io/projected/ <<<podid3;volume>>> \") <<<pod-from-event-create>>> (UID: \" <<<podid2>>> \") : write /var/lib/kubelet/pods/ <<<podid2>>> <*> no space left on device",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile operation for volume name kubernetes io projected volume pod node failed. no retries permitted until mplusignore durationbeforeretry failed mounting volume to pod setup failed volumeforvolume kubernetes io projected volume pod from event create write containers sandbox mount on the kubernetes node no space left on device"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> \"Error syncing pod, skipping\" err=\"failed <<<tostartcontainerfordeployment>>> with CreateContainerError: \\\"failed to generate security options <<<for-containername>>> <<<word:failed>>> to generate seccomp security options for container: <<<cannot-loca-seccomp-profile>>> no such file or directory\\\"\" <<<namespace-pod-eq>>> \" podUID= <<<podid2>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile pod could not reach running phase, skipping err failed tostart container commandfordeployment with container creation failed to generate security options for container failed to setup secure computing seccomp options for the container cannot loca seccomp profile tried to open file or change to directory which was not found namespace podu"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> \"Error syncing pod, skipping\" err=\"failed <<<tostartcontainerfordeployment>>> with <<<word:ImagePullBackOff>>> \\\"Back-off pulling image \\\\\\ <<<image-format-with-space-or-quotes>>> \\\\\\\"\\\"\" <<<namespace-pod-eq>>> \" podUID= <<<podid2>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile pod could not reach running phase, skipping err failed tostart container commandfordeployment with container image could not be pulled pausing image pull retry back off container image is being downloaded to the node container image namespace podu"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> \"Error syncing pod, skipping\" err=\"failed <<<tostartcontainerfordeployment>>> with <<<word:CreateContainerConfigError>>> \\\" <<<configmap-not-found>>> not found\\\"\" <<<namespace-pod-eq>>> \" podUID= <<<podid2>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile pod could not reach running phase, skipping err failed tostart container commandfordeployment with creating container configuration failed, either secret persistent volume or other pod configuration failed configmap configured for the pod does not exist namespace podu"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> \"Error syncing pod, skipping\" err=\"failed <<<tostartcontainerfordeployment>>> with <<<word:CreateContainerConfigError>>> \\\" <<<secretdirectnamequoted>>> not found\\\"\" <<<namespace-pod-eq>>> \" podUID= <<<podid2>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile pod could not reach running phase, skipping err failed tostart container commandfordeployment with creating container configuration failed, either secret persistent volume or other pod configuration failed secret not found namespace podu"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> \"Error syncing pod, skipping\" err=\"failed <<<tostartcontainerfordeployment>>> with ErrImagePull: \\\"rpc error: code = Unknown desc = Error response from daemon: unauthorized: authentication required\\\"\" <<<namespace-pod-eq>>> \" podUID= <<<podid2>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile pod could not reach running phase, skipping err failed tostart container commandfordeployment with error downloading container image remote procedure failed error response from remote process not authorized authentication required namespace podu"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> \"Error syncing pod, skipping\" err=\"failed <<<tostartcontainerfordeployment>>> with ErrImagePull: \\\"rpc error: code = Unknown desc = <*> <*> <*> <*> <<<headurl>>> dial tcp: <<<lookupdns>>> <<<ip;port>>> : no such host\\\"\" <<<namespace-pod-eq>>> \" podUID= <<<podid2>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile pod could not reach running phase, skipping err failed tostart container commandfordeployment with error downloading container image remote procedure failed http url trying to open tcp connection dns resolution failed namespace podu"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> \"Error syncing pod, skipping\" err=\"failed <<<tostartcontainerfordeployment>>> with ErrImagePull: \\\"rpc error: code = Unknown desc = <<<reading-manifest-failed>>> : manifest unknown: manifest unknown\\\"\" <<<namespace-pod-eq>>> \" podUID= <<<podid2>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile pod could not reach running phase, skipping err failed tostart container commandfordeployment with error downloading container image remote procedure failed reading manifest failed container image manifest was not found in the container repository container image manifest was not found in the container repository namespace podu"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> \"Error syncing pod, skipping\" err=\"failed <<<tostartcontainerfordeployment>>> with ErrImagePull: \\\"rpc error: code = Unknown desc = <<<reading-manifest-failed>>> : unauthorized: access to the requested resource is not authorized\\\"\" <<<namespace-pod-eq>>> \" podUID= <<<podid2>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile pod could not reach running phase, skipping err failed tostart container commandfordeployment with error downloading container image remote procedure failed reading manifest failed not authorized access to the requested resource is not authorized namespace podu"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> \"Error syncing pod, skipping\" err=\"failed <<<tostartcontainerfordeployment>>> with <<<word:ErrImageNeverPull>>> \\\"Container image \\\\\\ <<<image-format-with-space-or-quotes>>> \\\\\\\" is not present with pull policy of Never\\\"\" <<<namespace-pod-eq>>> \" podUID= <<<podid2>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile pod could not reach running phase, skipping err failed tostart container commandfordeployment with error image pull policy is set to never pull container image container image is not present with pull policy of never namespace podu"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> \"Error syncing pod, skipping\" err=\"failed <<<tostartcontainerfordeployment>>> with InvalidImageName: \\\"Failed to apply default image tag \\\\\\\"<dockerRepo>/container-create-error:<release>\\\\\\\": couldn't parse image reference \\\\\\\"<dockerRepo>/container-create-error:<release>\\\\\\\": invalid reference format: repository name must be lowercase\\\"\" <<<namespace-pod-eq>>> \" podUID= <<<podid2>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile pod could not reach running phase, skipping err failed tostart container commandfordeployment with image failed to apply default image tag container repository container create failed release could not parse image reference container repository container create failed release invalid reference format repository name must be lowercase namespace podu"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> \"Error syncing pod, skipping\" err=\"failed <<<tostartcontainerfordeployment>>> with <<<word:CrashLoopBackOff>>> \\\"back-off <*> restarting <<<word:failed>>> <<<container-equals>>> pod= <<<pod;namespace;podid>>> \\\"\" <<<namespace-pod-eq>>> \" podUID= <<<podid2>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile pod could not reach running phase, skipping err failed tostart container commandfordeployment with the container does not run properly and is failing continuously. kubernetes will delay the next restart of the container back off restarting failed container pod in namespace podu"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> \"Error syncing pod, skipping\" err=\"unmounted <<<volumes-for-pod>>> , unattached <<<volumes-for-pod>>> : <<<word:timed>>> out waiting for the condition\" <<<namespace-pod-eq>>> \" podUID= <<<podid2>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile pod could not reach running phase, skipping err unmounted volumes for pod unattached volumes for pod timed out waiting for the condition namespace podu"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> \"Pull <<<imagenotfound>>> image service failed\" err=\"rpc error: code = Unknown desc = Error response from daemon: unauthorized: authentication required\" image= <<<image-format-with-space-or-quotes>>> \"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile pull imagenotfound image service failed err remote procedure failed error response from remote process not authorized authentication required container image"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> \"Pull <<<imagenotfound>>> image service failed\" err=\"rpc error: code = Unknown desc = <*> <*> <*> <*> <<<headurl>>> dial tcp: <<<lookupdns>>> <<<ip;port>>> : no such host\" image= <<<image-format-with-space-or-quotes>>> \"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile pull imagenotfound image service failed err remote procedure failed http url trying to open tcp connection dns resolution failed container image"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> \"Pull <<<imagenotfound>>> image service failed\" err=\"rpc error: code = Unknown desc = <<<reading-manifest-failed>>> : manifest unknown: manifest unknown\" image= <<<image-format-with-space-or-quotes>>> \"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile pull imagenotfound image service failed err remote procedure failed reading manifest failed container image manifest was not found in the container repository container image manifest was not found in the container repository container image"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> \"Pull <<<imagenotfound>>> image service failed\" err=\"rpc error: code = Unknown desc = <<<reading-manifest-failed>>> : unauthorized: access to the requested resource is not authorized\" image= <<<image-format-with-space-or-quotes>>> \"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile pull imagenotfound image service failed err remote procedure failed reading manifest failed not authorized access to the requested resource is not authorized container image"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> \"ExecSync cmd from runtime service failed\" err=\"rpc error: code = DeadlineExceeded desc = context deadline exceeded\" <<<containeridlowerandcapital>>> <<<command-no-container-exists>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile trying to execute command inside container cmd from runtime service failed err remote procedure failed timeout deadline exceeded desc expected data failed to arrive in timely manner and exceeded the deadline set as the timeout causing the operation to eventually fail containeridlowerandcapital command no container exists"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> \"Unable to attach or mount volumes for pod; skipping pod\" err=\"unmounted <<<volumes-for-pod>>> , unattached <<<volumes-for-pod>>> : <<<word:timed>>> out waiting for the condition\" <<<namespace-pod-eq>>> \"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile unable to attach or mount volumes for pod skipping pod err unmounted volumes for pod unattached volumes for pod timed out waiting for the condition namespace"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> UnmountVolume.TearDown succeeded <<<volumeforvolume>>> ( <<<outervolumespacename>>> ) pod \" <<<podid2>>> \" (UID: \" <<<podid2>>> \"). <<<innervolumespacename>>> . PluginName <*> VolumeGidValue \"\"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile unmounting volume before deleting container succeeded volumeforvolume outervolumespacename pod innervolumespacename pluginname volumegidvalue"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> \" <<<verify-volume-attachment>>> <<<word:started>>> for volume <*> (UniqueName: <*> <<<podid3;volume>>> \\\") <<<pod-from-event-create>>> (UID: \\\" <<<podid2>>> \\\") \" <<<namespace-pod-eq>>> \"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile verifying that the volume is attached started for volume pod from event create namespace"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> \"Volume detached for volume <*> (UniqueName: <*> <<<podid3;volume>>> \\\") <<<onnodequotes>>> DevicePath \\\"\\\"\"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile volume detached for volume onnodequotes devicepath"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> \" <<<volume-unmount>>> <<<word:started>>> for volume <*> (UniqueName: <*> <<<podid3;volume>>> \\\") pod \\\" <<<podid2>>> \\\" (UID: \\\" <<<podid2>>> \\\") \"",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofile volume unmount started for volume pod"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> <<<namespace;slashpod>>> <<<volumespace>>> : error writing payload to ts data directory /var/lib/kubelet/pods/ <<<podid2>>> <*> write /var/lib/kubelet/pods/ <<<podid2>>> <*> no space left on device",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofilea pod in the namespacevolumespace error writing payload to ts data directory containers sandbox mount on the kubernetes node write containers sandbox mount on the kubernetes node no space left on device"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<severity-Level>>> <<<time>>> <<<gofile>>> <<<namespace;slashpod>>> <<<volumespace>>> : unable to write file /var/lib/kubelet/pods/ <<<podid2>>> <*> <<<permissionmode>>> write /var/lib/kubelet/pods/ <<<podid2>>> <*> no space left on device",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "severity level time gofilea pod in the namespacevolumespace unable to write file containers sandbox mount on the kubernetes node permissionmode write containers sandbox mount on the kubernetes node no space left on device"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<word:Started>>> <*> <*> <*>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "started"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<word:Started>>> crio-conmon- <<<digest>>> .scope.",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "started crio conmon digest scope."
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<word:Started>>> libcontainer <<<containeridspaceendline>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "started libcontainer container"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<word:Starting>>> <*> <*> <*>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "starting"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> <<<unmount>>>",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "unmount"
    },
    {
        "whatHappened": "<<<DateTimeutc>>> <<<sourceprocess>>> WARNING:Unknown index <<<genericnumber>>> seen, reloading interface list",
        "occurrences": 1,
        "percentage": 0.000025897342932615115,
        "description": "warning index genericnumber seen, reloading interface list"
    }
]